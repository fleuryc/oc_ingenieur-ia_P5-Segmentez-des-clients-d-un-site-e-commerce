{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && make dataset && cd notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- order might have multiple items.\n",
    "  -Ech item might be fulfilled by a distinct seller.\n",
    "  -ll text identifying stores and partners where replaced by the names of Game of Thrones great houses.\n",
    "\n",
    "![](https://i.imgur.com/HRhd2Y0.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System modules\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import csv\n",
    "\n",
    "# Append source directory to system path\n",
    "src_path = os.path.abspath(os.path.join(\"../src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Helper functions\n",
    "import data.helpers as data_helpers\n",
    "import features.helpers as feat_helpers\n",
    "import visualization.helpers as vis_helpers\n",
    "import models.helpers as models_helpers\n",
    "\n",
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn tools for model evaluation\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# Accelerate the development cycle\n",
    "SAMPLE_FRAC: float = .1\n",
    "\n",
    "# Prevent excessive memory usage used by plotly\n",
    "DRAW_PLOTS: bool = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = pd.read_csv(\n",
    "    \"../data/raw/olist_customers_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"customer_id\": \"category\",\n",
    "        \"customer_unique_id\": \"category\",\n",
    "        \"customer_city\": \"category\",\n",
    "        \"customer_state\": \"category\",\n",
    "        \"customer_zip_code_prefix\": \"category\",\n",
    "    },\n",
    ")\n",
    "geolocation_df = pd.read_csv(\n",
    "    \"../data/raw/olist_geolocation_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"geolocation_zip_code_prefix\": \"category\",\n",
    "        \"geolocation_city\": \"category\",\n",
    "        \"geolocation_state\": \"category\",\n",
    "        # Continuous quantitative data\n",
    "        \"geolocation_lat\": float,\n",
    "        \"geolocation_lng\": float,\n",
    "    },\n",
    ")\n",
    "order_items_df = pd.read_csv(\n",
    "    \"../data/raw/olist_order_items_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"order_id\": \"category\",\n",
    "        \"order_item_id\": \"category\",\n",
    "        \"product_id\": \"category\",\n",
    "        \"seller_id\": \"category\",\n",
    "        # Date data\n",
    "        \"shipping_limit_date\": str,\n",
    "        # Continuous quantitative data\n",
    "        \"price\": float,\n",
    "        \"freight_value\": float,\n",
    "    },\n",
    "    parse_dates=[\"shipping_limit_date\"],\n",
    ")\n",
    "order_payments_df = pd.read_csv(\n",
    "    \"../data/raw/olist_order_payments_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"order_id\": \"category\",\n",
    "        \"payment_type\": \"category\",\n",
    "        # Discrete quantitative data\n",
    "        \"payment_sequential\": int,\n",
    "        \"payment_installments\": int,\n",
    "        # Continuous quantitative data\n",
    "        \"payment_value\": float,\n",
    "    },\n",
    ")\n",
    "order_reviews_df = pd.read_csv(\n",
    "    \"../data/raw/olist_order_reviews_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"review_id\": \"category\",\n",
    "        \"order_id\": \"category\",\n",
    "        # Discrete quantitative data\n",
    "        \"review_score\": int,\n",
    "        # Text data\n",
    "        \"review_comment_title\": str,\n",
    "        \"review_comment_message\": str,\n",
    "        # Date data\n",
    "        \"review_creation_date\": str,\n",
    "        \"review_answer_timestamp\": str,\n",
    "    },\n",
    "    parse_dates=[\"review_creation_date\", \"review_answer_timestamp\"],\n",
    ")\n",
    "orders_df = pd.read_csv(\n",
    "    \"../data/raw/olist_orders_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"order_id\": \"category\",\n",
    "        \"customer_id\": \"category\",\n",
    "        \"order_status\": \"category\",\n",
    "        # Date data\n",
    "        \"order_purchase_timestamp\": str,\n",
    "        \"order_approved_at\": str,\n",
    "        \"order_delivered_carrier_date\": str,\n",
    "        \"order_delivered_customer_date\": str,\n",
    "        \"order_estimated_delivery_date\": str,\n",
    "    },\n",
    "    parse_dates=[\n",
    "        \"order_purchase_timestamp\",\n",
    "        \"order_approved_at\",\n",
    "        \"order_delivered_carrier_date\",\n",
    "        \"order_delivered_customer_date\",\n",
    "        \"order_estimated_delivery_date\",\n",
    "    ],\n",
    ")\n",
    "products_df = pd.read_csv(\n",
    "    \"../data/raw/olist_products_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"product_id\": \"category\",\n",
    "        \"product_category_name\": \"category\",\n",
    "        # Discrete quantitative data\n",
    "        # Nullable : https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#support-for-integer-na\n",
    "        \"product_name_lenght\": pd.Int64Dtype(),\n",
    "        \"product_description_lenght\": pd.Int64Dtype(),\n",
    "        \"product_photos_qty\": pd.Int64Dtype(),\n",
    "        # Continuous quantitative data\n",
    "        \"product_weight_g\": float,\n",
    "        \"product_length_cm\": float,\n",
    "        \"product_height_cm\": float,\n",
    "        \"product_width_cm\": float,\n",
    "    },\n",
    ")\n",
    "sellers_df = pd.read_csv(\n",
    "    \"../data/raw/olist_sellers_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"seller_id\": \"category\",\n",
    "        \"seller_city\": \"category\",\n",
    "        \"seller_state\": \"category\",\n",
    "        \"seller_zip_code_prefix\": \"category\",\n",
    "    },\n",
    ")\n",
    "category_translation_df = pd.read_csv(\n",
    "    \"../data/raw/product_category_name_translation.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df[[\"order_id\", \"customer_id\", \"order_purchase_timestamp\"]].describe(\n",
    "    include=\"all\", datetime_is_numeric=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_payments_df[[\"order_id\", \"payment_value\"]].describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_orders_payments_df = (\n",
    "    orders_df[[\"order_id\", \"customer_id\", \"order_purchase_timestamp\"]]\n",
    "    .merge(\n",
    "        order_payments_df[[\"order_id\", \"payment_value\"]],\n",
    "        how=\"left\",\n",
    "        left_on=\"order_id\",\n",
    "        right_on=\"order_id\",\n",
    "        validate=\"1:m\",\n",
    "    )\n",
    "    .groupby(\"order_id\")\n",
    "    .agg(\n",
    "        customer_id=(\"customer_id\", \"first\"),\n",
    "        order_purchase_timestamp=(\"order_purchase_timestamp\", \"first\"),\n",
    "        payment_value=(\"payment_value\", \"sum\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "merged_orders_payments_df.describe(include=\"all\", datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM (Recency, Frequency, Monetary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df = (\n",
    "    customers_df[[\"customer_id\", \"customer_unique_id\"]]\n",
    "    .merge(\n",
    "        merged_orders_payments_df,\n",
    "        how=\"left\",\n",
    "        left_on=\"customer_id\",\n",
    "        right_on=\"customer_id\",\n",
    "        validate=\"1:1\",\n",
    "    )\n",
    "    .groupby(\"customer_unique_id\")\n",
    "    .agg(\n",
    "        recency=(\"order_purchase_timestamp\", \"max\"),\n",
    "        frequency=(\"customer_id\", \"count\"),\n",
    "        monetary=(\"payment_value\", \"mean\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "rfm_df[\"recency\"] = (\n",
    "    (rfm_df[\"recency\"] - rfm_df[\"recency\"].max()) / np.timedelta64(1, \"D\")\n",
    ").values\n",
    "rfm_df = data_helpers.reduce_dataframe_memory_usage(rfm_df)\n",
    "\n",
    "rfm_df.describe(include=\"all\", datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DRAW_PLOTS:\n",
    "    for col in rfm_df.columns:\n",
    "        fig = px.histogram(\n",
    "            rfm_df[col],\n",
    "            marginal=\"box\",\n",
    "            width=800,\n",
    "        )\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling, Cleaning & Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_rfm_df = pd.DataFrame(\n",
    "    scaler.fit_transform(rfm_df), columns=rfm_df.columns\n",
    ")\n",
    "\n",
    "# Remove outliers and duplicates\n",
    "scaled_rfm_df = (\n",
    "    scaled_rfm_df[scaled_rfm_df < 20]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .sample(frac=SAMPLE_FRAC, random_state=42)\n",
    ")\n",
    "\n",
    "rfm_df = pd.DataFrame(\n",
    "    scaler.inverse_transform(scaled_rfm_df), columns=scaled_rfm_df.columns\n",
    ")\n",
    "\n",
    "rfm_df.describe(include=\"all\", datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA & Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DRAW_PLOTS:\n",
    "    fig = px.scatter_matrix(\n",
    "        rfm_df,\n",
    "        color=\"frequency\",\n",
    "        size=\"frequency\",\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        diagonal_visible=False,\n",
    "        showupperhalf=False,\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DRAW_PLOTS:\n",
    "    fig = px.scatter(\n",
    "        rfm_df,\n",
    "        x=\"recency\",\n",
    "        y=\"monetary\",\n",
    "        labels={\n",
    "            \"recency\": \"Recency : days since last purchase\",\n",
    "            \"frequency\": \"Frequency : number of purchases\",\n",
    "            \"monetary\": \"Monetary : average purchase amount\",\n",
    "        },\n",
    "        color=\"frequency\",\n",
    "        size=\"frequency\",\n",
    "        trendline=\"ols\",\n",
    "        marginal_x=\"histogram\",\n",
    "        marginal_y=\"histogram\",\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "if DRAW_PLOTS:\n",
    "    knn = NearestNeighbors(n_neighbors=2).fit(scaled_rfm_df)\n",
    "    distances, indices = knn.kneighbors(scaled_rfm_df)\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:, 1]\n",
    "\n",
    "    fig = px.line(\n",
    "        distances,\n",
    "        labels={\n",
    "            \"index\": \"Couple of customers\",\n",
    "            \"value\": \"Euclidian distance\",\n",
    "        },\n",
    "        title=\"Customers distances in scaled RFM space\",\n",
    "        width=800,\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA (Principal Component Analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "if DRAW_PLOTS:\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    data_pca = pca.fit_transform(scaled_rfm_df)\n",
    "\n",
    "    # Plot the data in the PCA space\n",
    "    fig = px.scatter(\n",
    "        x=data_pca[:1000, 0],\n",
    "        y=data_pca[:1000, 1],\n",
    "        trendline=\"ols\",\n",
    "        title=\"PCA 2D\",\n",
    "        opacity=0.5,\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        labels={\"x\": \"PCA 1\", \"y\": \"PCA 2\"},\n",
    "    )\n",
    "\n",
    "    # Plot the feature importances in the PCA space\n",
    "    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "    for i, feature in enumerate(rfm_df.columns):\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=0,\n",
    "            y0=0,\n",
    "            x1=loadings[i, 0],\n",
    "            y1=loadings[i, 1],\n",
    "            line=dict(color=\"red\", width=3),\n",
    "            name=feature,\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            x=loadings[i, 0],\n",
    "            y=loadings[i, 1],\n",
    "            ax=0,\n",
    "            ay=0,\n",
    "            xanchor=\"center\",\n",
    "            yanchor=\"bottom\",\n",
    "            text=feature,\n",
    "            name=feature,\n",
    "        )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dendrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "\n",
    "if DRAW_PLOTS:\n",
    "    dendrogram(\n",
    "        linkage(scaled_rfm_df.sample(frac=0.1, random_state=42), method=\"ward\"),\n",
    "        truncate_mode=\"level\",\n",
    "        p=3,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import ClusterMixin\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,  # higher is better : https://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient\n",
    "    davies_bouldin_score,  # lower is better : https://scikit-learn.org/stable/modules/clustering.html#davies-bouldin-index\n",
    "    calinski_harabasz_score, # higher is better : https://scikit-learn.org/stable/modules/clustering.html#calinski-harabasz-index\n",
    ")\n",
    "\n",
    "\n",
    "models_results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"n_clusters\",\n",
    "        \"labels\",\n",
    "        \"cluster_centers\",\n",
    "        \"inertia\",\n",
    "        \"time\",\n",
    "        \"silhouette_score\",\n",
    "        \"davies_bouldin_score\",\n",
    "        \"calinski_harabasz_score\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def process_model(\n",
    "    model_class: ClusterMixin,\n",
    "    model_args: dict,\n",
    "    param_name: str,\n",
    "    param_range: list,\n",
    "    fit_df: pd.DataFrame,\n",
    "    pred_df: pd.DataFrame,\n",
    "    verbose: bool = False,\n",
    ") -> dict:\n",
    "    results = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"model\",\n",
    "            \"n_clusters\",\n",
    "            \"labels\",\n",
    "            \"cluster_centers\",\n",
    "            \"inertia\",\n",
    "            \"time\",\n",
    "            \"silhouette_score\",\n",
    "            \"davies_bouldin_score\",\n",
    "            \"calinski_harabasz_score\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for param_value in param_range:\n",
    "        model_args[param_name] = param_value\n",
    "        model = model_class(**model_args)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\">>> Model : { model }\")\n",
    "\n",
    "        if hasattr(model, \"fit\") and hasattr(model, \"predict\"):\n",
    "            start_time = time()\n",
    "            model.fit(fit_df)\n",
    "            fit_time = (time() - start_time) / fit_df.shape[0]\n",
    "\n",
    "            start_time = time()\n",
    "            predicted_labels = model.predict(pred_df)\n",
    "            pred_time = (time() - start_time) / pred_df.shape[0]\n",
    "\n",
    "            fit_pred_time = fit_time + pred_time\n",
    "        elif hasattr(model, \"fit_predict\"):\n",
    "            start_time = time()\n",
    "            predicted_labels = model.fit_predict(pred_df)\n",
    "            fit_pred_time = time() - start_time\n",
    "        else:\n",
    "            raise ValueError(f\"{model} is not a clustering model.\")\n",
    "\n",
    "        n_clusters = predicted_labels.max() + 1\n",
    "        if verbose:\n",
    "            print(f\"Number of clusters : { n_clusters }\")\n",
    "\n",
    "        if not 1 < n_clusters < 11:\n",
    "            continue\n",
    "\n",
    "        result = {\n",
    "            \"model\": str(model)\n",
    "            .replace(\", random_state=42\", \"\")\n",
    "            .replace(\", n_jobs=-1\", \"\")\n",
    "            .replace(\"(random_state=42\", \"(\")\n",
    "            .replace(\"(n_jobs=-1\", \"(\"),\n",
    "            \"n_clusters\": n_clusters,\n",
    "            \"labels\": predicted_labels,\n",
    "            \"cluster_centers\": model.cluster_centers_\n",
    "            if hasattr(model, \"cluster_centers_\")\n",
    "            else None,\n",
    "            \"inertia\": model.inertia_ if hasattr(model, \"inertia_\") else None,\n",
    "            \"fit_pred_time\": fit_pred_time,\n",
    "            \"silhouette_score\": silhouette_score(\n",
    "                pred_df, predicted_labels, random_state=42\n",
    "            ),\n",
    "            \"davies_bouldin_score\": davies_bouldin_score(\n",
    "                pred_df, predicted_labels\n",
    "            ),\n",
    "            \"calinski_harabasz_score\": calinski_harabasz_score(\n",
    "                pred_df, predicted_labels\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Score : { round(result['silhouette_score'], 3) }\")\n",
    "\n",
    "        results = results.append(result, ignore_index=True)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_scores(results: pd.DataFrame) -> None:\n",
    "    fig = px.line(\n",
    "        results,\n",
    "        x=\"model\",\n",
    "        y=[\n",
    "            \"silhouette_score\",\n",
    "            \"davies_bouldin_score\",\n",
    "        ],\n",
    "        title=\"Clustering models evaluation\",\n",
    "        markers=True,\n",
    "        width=800,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_clusters(model_name, pred_df, labels, cluster_centers=None) -> None:\n",
    "    fig = px.scatter_3d(\n",
    "        pred_df,\n",
    "        x=\"recency\",\n",
    "        y=\"frequency\",\n",
    "        z=\"monetary\",\n",
    "        title=f\"Clustering : { model_name }\",\n",
    "        color=labels,\n",
    "        opacity=0.5,\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    if cluster_centers is not None:\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=cluster_centers[:, 0],\n",
    "                y=cluster_centers[:, 1],\n",
    "                z=cluster_centers[:, 2],\n",
    "                mode=\"markers\",\n",
    "                marker_symbol=\"x\",\n",
    "                hovertemplate=\"recency: %{x}, frequency: %{y}, monetary: %{z}\",\n",
    "                text=\"Cluster Center\",\n",
    "                name=\"Cluster Center\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_boxes(model_name, pred_df, labels, cluster_centers=None) -> None:\n",
    "    pred_df[\"labels\"] = labels\n",
    "\n",
    "    fig = px.box(\n",
    "        rfm_df,\n",
    "        title=f\"{ model_name } - Recency : days since last purchase\",\n",
    "        x=\"recency\",\n",
    "        color=\"labels\",\n",
    "        width=800,\n",
    "    )\n",
    "    fig.update_traces(boxmean=\"sd\")\n",
    "    fig.update_traces(notched=True)\n",
    "    fig.show()\n",
    "\n",
    "    fig = px.box(\n",
    "        rfm_df,\n",
    "        title=f\"{ model_name } - Frequency : total number of purchases\",\n",
    "        x=\"frequency\",\n",
    "        color=\"labels\",\n",
    "        width=800,\n",
    "    )\n",
    "    fig.update_traces(boxmean=\"sd\")\n",
    "    fig.update_traces(notched=True)\n",
    "    fig.show()\n",
    "\n",
    "    fig = px.box(\n",
    "        rfm_df,\n",
    "        title=f\"{ model_name } - Monetary : average purchase value\",\n",
    "        x=\"monetary\",\n",
    "        color=\"labels\",\n",
    "        width=800,\n",
    "    )\n",
    "    fig.update_traces(boxmean=\"sd\")\n",
    "    fig.update_traces(notched=True)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=KMeans,\n",
    "    model_args={\"random_state\": 42},\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df,\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniBatchKMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=MiniBatchKMeans,\n",
    "    model_args={\"random_state\": 42},\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df,\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AffinityPropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=AffinityPropagation,\n",
    "    model_args={\"random_state\": 42},\n",
    "    param_name=\"damping\",\n",
    "    param_range=[round(e, 3) for e in np.linspace(0.85, 0.99, 10)],\n",
    "    fit_df=scaled_rfm_df.sample(frac=0.1, random_state=42),\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "fit_pred_df = scaled_rfm_df.sample(frac=0.5, random_state=42)\n",
    "results = process_model(\n",
    "    model_class=AgglomerativeClustering,\n",
    "    model_args={},\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=fit_pred_df,\n",
    "    pred_df=fit_pred_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeanShift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=MeanShift,\n",
    "    model_args={\"n_jobs\": -1},\n",
    "    param_name=\"bandwidth\",\n",
    "    param_range=[round(e, 1) for e in np.linspace(0.5, 5, 10)],\n",
    "    fit_df=scaled_rfm_df.sample(frac=0.1, random_state=42),\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpectralClustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "\n",
    "fit_pred_df = scaled_rfm_df.sample(frac=0.2, random_state=42)\n",
    "results = process_model(\n",
    "    model_class=SpectralClustering,\n",
    "    model_args={\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    },\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=fit_pred_df,\n",
    "    pred_df=fit_pred_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if second_best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "fit_pred_df = scaled_rfm_df.sample(frac=0.5, random_state=42)\n",
    "results = process_model(\n",
    "    model_class=DBSCAN,\n",
    "    model_args={\n",
    "        \"n_jobs\": -1,\n",
    "    },\n",
    "    param_name=\"eps\",\n",
    "    param_range=[round(e, 2) for e in np.linspace(0.1, 1.5, 10)],\n",
    "    fit_df=fit_pred_df,\n",
    "    pred_df=fit_pred_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if second_best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "\n",
    "fit_pred_df = scaled_rfm_df.sample(frac=0.5, random_state=42)\n",
    "results = process_model(\n",
    "    model_class=OPTICS,\n",
    "    model_args={\n",
    "        \"n_jobs\": -1,\n",
    "    },\n",
    "    param_name=\"min_samples\",\n",
    "    param_range=[round(e, 4) for e in np.linspace(0.001, 0.004, 10)],\n",
    "    fit_df=fit_pred_df,\n",
    "    pred_df=fit_pred_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if second_best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=Birch,\n",
    "    model_args={},\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df.sample(frac=0.2, random_state=42),\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM (Gaussian Mixture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=GaussianMixture,\n",
    "    model_args={\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "    param_name=\"n_components\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df,\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Gaussian Mixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=BayesianGaussianMixture,\n",
    "    model_args={\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "    param_name=\"n_components\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df,\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results.sort_values(by=\"silhouette_score\", ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ecc8f64076e26b332eb2910f8df6eb83deb22305ec688dab0bef29bb670fcf7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
