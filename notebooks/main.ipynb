{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olist : Construire un modèle de segmentation client\n",
    "\n",
    "## Contexte\n",
    "\n",
    "Olist est une place de marché en ligne qui permet à des e-marchands de proposer leurs produits aux internautes Brésiliens.\n",
    "Afin d'optimiser les campagnes de communication, il est nécessaire de bien adapter le discours à chaque catégorie de clients, et donc de bien comprendre chaque typologie de clients. Pour répondre à cette problématique, il faut définir une stratégie de segmentation des clients efficace. \n",
    "\n",
    "L'équipe marketing utilisera le modèle de segmentation. Ils auront besoin d'un outil fiable, rapide et facile à utiliser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des modules du projet\n",
    "\n",
    "Afin de simplifier le Notebook, les fonctions utiles sont placées dans le dossier [src/](../src/).\n",
    "\n",
    "Nous allons utiliser le langage [Python](https://www.python.org/about/gettingstarted/), et présenter ici le code, les résultats et l'analyse sous forme de [Notebook JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html).\n",
    "\n",
    "Nous allons aussi utiliser les bibliothèques usuelles d'exploration et analyse de données, afin d'améliorer la simplicité et la performance de notre code :\n",
    "\n",
    "-   [NumPy](https://numpy.org/doc/stable/user/quickstart.html) et [Pandas](https://pandas.pydata.org/docs/user_guide/index.html) : effectuer des calculs scientifiques (statistiques, algèbre, ...) et manipuler des séries et tableaux de données volumineuses et complexes\n",
    "-   [scikit-learn](https://scikit-learn.org/stable/getting_started.html) : pour modéliser les données \n",
    "-   [Plotly](https://plotly.com/python/getting-started/) : générer des graphiques lisibles, interactifs et pertinents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System modules\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# Append source directory to system path\n",
    "src_path = os.path.abspath(os.path.join(\"../src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Helper functions\n",
    "import data.helpers as data_helpers\n",
    "import features.helpers as feat_helpers\n",
    "import visualization.helpers as vis_helpers\n",
    "import models.helpers as models_helpers\n",
    "\n",
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# Accelerate the development cycle\n",
    "SAMPLE_FRAC: float = 0.5\n",
    "\n",
    "# Prevent excessive memory usage used by plotly\n",
    "DRAW_PLOTS: bool = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "Nous allons télécharger et dé-zipper les fichiers CSV, puis les charger en mémoire, en prenant soin d'utiliser le bon type pour chaque variable.\n",
    "\n",
    "Le schema de données nous est donné : \n",
    "\n",
    "![](https://i.imgur.com/HRhd2Y0.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip CSV files\n",
    "!cd .. && make dataset && cd notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customers data\n",
    "customers_df = pd.read_csv(\n",
    "    \"../data/raw/olist_customers_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"customer_id\": \"category\",\n",
    "        \"customer_unique_id\": \"category\",\n",
    "        \"customer_city\": \"category\",\n",
    "        \"customer_state\": \"category\",\n",
    "        \"customer_zip_code_prefix\": \"category\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Load geolocation data\n",
    "geolocation_df = pd.read_csv(\n",
    "    \"../data/raw/olist_geolocation_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"geolocation_zip_code_prefix\": \"category\",\n",
    "        \"geolocation_city\": \"category\",\n",
    "        \"geolocation_state\": \"category\",\n",
    "        # Continuous quantitative data\n",
    "        \"geolocation_lat\": float,\n",
    "        \"geolocation_lng\": float,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Load order items data\n",
    "order_items_df = pd.read_csv(\n",
    "    \"../data/raw/olist_order_items_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"order_id\": \"category\",\n",
    "        \"order_item_id\": \"category\",\n",
    "        \"product_id\": \"category\",\n",
    "        \"seller_id\": \"category\",\n",
    "        # Date data\n",
    "        \"shipping_limit_date\": str,\n",
    "        # Continuous quantitative data\n",
    "        \"price\": float,\n",
    "        \"freight_value\": float,\n",
    "    },\n",
    "    parse_dates=[\"shipping_limit_date\"],\n",
    ")\n",
    "\n",
    "# Load order payments\n",
    "order_payments_df = pd.read_csv(\n",
    "    \"../data/raw/olist_order_payments_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"order_id\": \"category\",\n",
    "        \"payment_type\": \"category\",\n",
    "        # Discrete quantitative data\n",
    "        \"payment_sequential\": int,\n",
    "        \"payment_installments\": int,\n",
    "        # Continuous quantitative data\n",
    "        \"payment_value\": float,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Load order reviews\n",
    "order_reviews_df = pd.read_csv(\n",
    "    \"../data/raw/olist_order_reviews_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"review_id\": \"category\",\n",
    "        \"order_id\": \"category\",\n",
    "        # Discrete quantitative data\n",
    "        \"review_score\": int,\n",
    "        # Text data\n",
    "        \"review_comment_title\": str,\n",
    "        \"review_comment_message\": str,\n",
    "        # Date data\n",
    "        \"review_creation_date\": str,\n",
    "        \"review_answer_timestamp\": str,\n",
    "    },\n",
    "    parse_dates=[\"review_creation_date\", \"review_answer_timestamp\"],\n",
    ")\n",
    "\n",
    "# Load orders data\n",
    "orders_df = pd.read_csv(\n",
    "    \"../data/raw/olist_orders_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"order_id\": \"category\",\n",
    "        \"customer_id\": \"category\",\n",
    "        \"order_status\": \"category\",\n",
    "        # Date data\n",
    "        \"order_purchase_timestamp\": str,\n",
    "        \"order_approved_at\": str,\n",
    "        \"order_delivered_carrier_date\": str,\n",
    "        \"order_delivered_customer_date\": str,\n",
    "        \"order_estimated_delivery_date\": str,\n",
    "    },\n",
    "    parse_dates=[\n",
    "        \"order_purchase_timestamp\",\n",
    "        \"order_approved_at\",\n",
    "        \"order_delivered_carrier_date\",\n",
    "        \"order_delivered_customer_date\",\n",
    "        \"order_estimated_delivery_date\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Load products data\n",
    "products_df = pd.read_csv(\n",
    "    \"../data/raw/olist_products_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"product_id\": \"category\",\n",
    "        \"product_category_name\": \"category\",\n",
    "        # Discrete quantitative data\n",
    "        # Nullable : https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#support-for-integer-na\n",
    "        \"product_name_lenght\": pd.Int64Dtype(),\n",
    "        \"product_description_lenght\": pd.Int64Dtype(),\n",
    "        \"product_photos_qty\": pd.Int64Dtype(),\n",
    "        # Continuous quantitative data\n",
    "        \"product_weight_g\": float,\n",
    "        \"product_length_cm\": float,\n",
    "        \"product_height_cm\": float,\n",
    "        \"product_width_cm\": float,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Load sellers data\n",
    "sellers_df = pd.read_csv(\n",
    "    \"../data/raw/olist_sellers_dataset.csv\",\n",
    "    dtype={\n",
    "        # Nominal qualitative data\n",
    "        \"seller_id\": \"category\",\n",
    "        \"seller_city\": \"category\",\n",
    "        \"seller_state\": \"category\",\n",
    "        \"seller_zip_code_prefix\": \"category\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Load category name translation data\n",
    "category_translation_df = pd.read_csv(\n",
    "    \"../data/raw/product_category_name_translation.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction des variables RFM (Recency, Frequency, Monetary)\n",
    "\n",
    "La segmentation des clients selon les variables RFM (Recency, Frequency, Monetary) est une méthode classique en marketing.\n",
    "\n",
    "Pour un client donné, nous définissons les variables comme :\n",
    "\n",
    "-   Recency : nombre de jours depuis le dernier achat du client\n",
    "-   Frequency : nombre total d'achats du client\n",
    "-   Monetary : montant moyen des achats du client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sum of the payment values for each order\n",
    "merged_orders_payments_df = (\n",
    "    orders_df[[\"order_id\", \"customer_id\", \"order_purchase_timestamp\"]]\n",
    "    .merge(\n",
    "        order_payments_df[[\"order_id\", \"payment_value\"]],\n",
    "        how=\"left\",\n",
    "        left_on=\"order_id\",\n",
    "        right_on=\"order_id\",\n",
    "        validate=\"1:m\",\n",
    "    )\n",
    "    .groupby(\"order_id\")\n",
    "    .agg(\n",
    "        customer_id=(\"customer_id\", \"first\"),\n",
    "        order_purchase_timestamp=(\"order_purchase_timestamp\", \"first\"),\n",
    "        payment_value=(\"payment_value\", \"sum\"),  # Total order value\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compute the RFM variables\n",
    "rfm_df = (\n",
    "    customers_df[[\"customer_id\", \"customer_unique_id\"]]\n",
    "    .merge(\n",
    "        merged_orders_payments_df,\n",
    "        how=\"left\",\n",
    "        left_on=\"customer_id\",\n",
    "        right_on=\"customer_id\",\n",
    "        validate=\"1:1\",\n",
    "    )\n",
    "    .groupby(\"customer_unique_id\")\n",
    "    .agg(\n",
    "        recency=(  # Recency : last purchase date\n",
    "            \"order_purchase_timestamp\",\n",
    "            \"max\",\n",
    "        ),\n",
    "        frequency=(  # Frequency : total number of purchases\n",
    "            \"customer_id\",\n",
    "            \"count\",\n",
    "        ),\n",
    "        monetary=(\"payment_value\", \"mean\"),  # Monetary : average purchase value\n",
    "    )\n",
    ")\n",
    "\n",
    "# Recency : Transform last purchase date to days since last purchase (from the very last order recorded)\n",
    "rfm_df[\"recency\"] = (\n",
    "    (rfm_df[\"recency\"] - rfm_df[\"recency\"].max()) / np.timedelta64(1, \"D\")\n",
    ").values\n",
    "\n",
    "# Reduce memory usage\n",
    "rfm_df = data_helpers.reduce_dataframe_memory_usage(rfm_df)\n",
    "\n",
    "rfm_df.describe(include=\"all\", datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'y a pas de valeurs vides et toutes les valeurs semblent \"possibles\" (pas de valeur impossible : une date d'achat dans le futur, ou un montant négatif...).\n",
    "\n",
    "Observons la distribution de nos variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions des variables\n",
    "\n",
    "Observons les points de données dans l'espace RFM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the RFM variables scatter matrix to see their correlation\n",
    "if DRAW_PLOTS:\n",
    "    fig = px.scatter_3d(\n",
    "        rfm_df.sample(  # sample of the data for performances reasons\n",
    "            n=1000,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        x=\"recency\",\n",
    "        y=\"frequency\",\n",
    "        z=\"monetary\",\n",
    "        title=\"Clients in RFM space\",\n",
    "        opacity=0.5,\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the RFM variables histograms and boxes with Plotly\n",
    "if DRAW_PLOTS:\n",
    "    for col in rfm_df.columns:\n",
    "        fig = px.histogram(\n",
    "            rfm_df[col],\n",
    "            marginal=\"box\",\n",
    "            width=800,\n",
    "        )\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que le nombre d'achats a tendance à augmenter dans le temps. La plupart (93%) des clients achètent n'ont effectué qu'un seul achat. Le panier moyen est de 161 Reals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the RFM variables scatter matrix to see their correlation\n",
    "if DRAW_PLOTS:\n",
    "    fig = px.scatter_matrix(\n",
    "        rfm_df.sample(  # sample of the data for performances reasons\n",
    "            n=1000,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        diagonal_visible=False,\n",
    "        showupperhalf=False,\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que les clients \"fréquents\" ont tendance à être plus \"récents\", ce qui est plutôt logique (le second achat est forcément postérieur au premier...).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Recency x Monetary trendline to see if there is a correlation\n",
    "if DRAW_PLOTS:\n",
    "    fig = px.scatter(\n",
    "        rfm_df.sample(  # sample of the data for performances reasons\n",
    "            n=1000,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        x=\"recency\",\n",
    "        y=\"monetary\",\n",
    "        labels={\n",
    "            \"recency\": \"Recency : days since last purchase\",\n",
    "            \"frequency\": \"Frequency : total number of purchases\",\n",
    "            \"monetary\": \"Monetary : average purchase value\",\n",
    "        },\n",
    "        # color=\"frequency\",\n",
    "        # size=\"frequency\",\n",
    "        trendline=\"ols\",\n",
    "        trendline_color_override=\"red\",\n",
    "        marginal_x=\"histogram\",\n",
    "        marginal_y=\"histogram\",\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling, Cleaning & Sampling\n",
    "\n",
    "Nous voyons que nos variables ont des ordres de grandeur très différents et qu'il y a quelques valeurs \"extrêmes\" qui pourront perturber l'entraînement de nos modèles. Nous allons donc transformer nos données pour les rendre plus facilement exploitables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "# # Scale the RFM variables\n",
    "# scaler = StandardScaler()\n",
    "# scaled_rfm_df = pd.DataFrame(\n",
    "#     scaler.fit_transform(rfm_df), columns=rfm_df.columns\n",
    "# )\n",
    "\n",
    "# # Remove outliers and duplicates\n",
    "# scaled_rfm_df = (\n",
    "#     scaled_rfm_df[scaled_rfm_df < 20]  # Remove outliers\n",
    "#     .dropna()  # Remove rows with NaN values\n",
    "#     .drop_duplicates()  # Remove duplicates\n",
    "#     .sample(frac=SAMPLE_FRAC, random_state=42)  # Sample the data\n",
    "# )\n",
    "\n",
    "# # Inverse-transform the data to get the same sample of original values\n",
    "# rfm_df = pd.DataFrame(\n",
    "#     scaler.inverse_transform(scaled_rfm_df), columns=scaled_rfm_df.columns\n",
    "# )\n",
    "\n",
    "# rfm_df.describe(include=\"all\", datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfm_fit(\n",
    "    df: pd.DataFrame,\n",
    ") -> tuple[StandardScaler, MinMaxScaler]:\n",
    "    df = df.copy()\n",
    "    df[\"recency\"] = -df[\"recency\"]  # Invert the recency to have positive values\n",
    "    log_df = np.log1p(df.astype(float))\n",
    "    standard_scaler = StandardScaler().fit(log_df)\n",
    "    minmax_scaler = MinMaxScaler().fit(standard_scaler.transform(log_df))\n",
    "    return standard_scaler, minmax_scaler\n",
    "\n",
    "\n",
    "def rfm_transform(\n",
    "    df: pd.DataFrame,\n",
    "    standard_scaler: StandardScaler,\n",
    "    minmax_scaler: MinMaxScaler,\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"recency\"] = -df[\"recency\"]  # Invert the recency to have positive values\n",
    "    return pd.DataFrame(\n",
    "        minmax_scaler.transform(\n",
    "            standard_scaler.transform(np.log1p(df.astype(float)))\n",
    "        ),\n",
    "        columns=df.columns,\n",
    "    )\n",
    "\n",
    "\n",
    "def rfm_inverse_transform(\n",
    "    df: pd.DataFrame,\n",
    "    minmax_scaler: MinMaxScaler,\n",
    "    standard_scaler: StandardScaler,\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df = np.expm1(\n",
    "        pd.DataFrame(\n",
    "            standard_scaler.inverse_transform(\n",
    "                minmax_scaler.inverse_transform(df)\n",
    "            ),\n",
    "            columns=df.columns,\n",
    "        )\n",
    "    )\n",
    "    df[\"recency\"] = -df[\"recency\"]  # Invert the recency to have negative values\n",
    "    return df\n",
    "\n",
    "\n",
    "standard_scaler, minmax_scaler = rfm_fit(rfm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_rfm_df = rfm_df.sample(frac=0.1, random_state=42)\n",
    "sampled_rfm_df.describe(include=\"all\", datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    sampled_rfm_df,\n",
    "    x=\"recency\",\n",
    "    y=\"frequency\",\n",
    "    z=\"monetary\",\n",
    "    title=\"Clients in RFM space\",\n",
    "    opacity=0.5,\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_rfm_df = rfm_transform(\n",
    "    sampled_rfm_df,\n",
    "    standard_scaler=standard_scaler,\n",
    "    minmax_scaler=minmax_scaler,\n",
    ")  # Scale the RFM variables\n",
    "scaled_rfm_df.describe(include=\"all\", datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    scaled_rfm_df,\n",
    "    x=\"recency\",\n",
    "    y=\"frequency\",\n",
    "    z=\"monetary\",\n",
    "    title=\"Clients in RFM space\",\n",
    "    opacity=0.5,\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_rfm_df = rfm_inverse_transform(\n",
    "    scaled_rfm_df,\n",
    "    minmax_scaler=minmax_scaler,\n",
    "    standard_scaler=standard_scaler,\n",
    ")  # UnScale the RFM variables\n",
    "unscaled_rfm_df.describe(include=\"all\", datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    unscaled_rfm_df,\n",
    "    x=\"recency\",\n",
    "    y=\"frequency\",\n",
    "    z=\"monetary\",\n",
    "    title=\"Clients in RFM space\",\n",
    "    opacity=0.5,\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos données sont maintenant prêtes à être exploitées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA & Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distances\n",
    "\n",
    "Nous allons chercher à observer quelle est la répartition de la distance euclidienne entre nos clients dans l'espace RFM transformé. Cette information nous donnera une indication utile pour les modèles de segmentation utilisant le voisinage des points (comme DBSCAN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# Compute the nearest neighbors of each customer and their distance\n",
    "if DRAW_PLOTS:\n",
    "    knn = NearestNeighbors(n_neighbors=2).fit(scaled_rfm_df)\n",
    "    distances, indices = knn.kneighbors(scaled_rfm_df)\n",
    "    distances = np.sort(distances[:1000], axis=0)\n",
    "    distances = distances[:, 1]\n",
    "\n",
    "    # Plot the nearest neighbors distances\n",
    "    fig = px.line(\n",
    "        distances,\n",
    "        labels={\n",
    "            \"index\": \"Couple of customers\",\n",
    "            \"value\": \"Euclidian distance\",\n",
    "        },\n",
    "        title=\"Customers distances in scaled RFM space\",\n",
    "        width=800,\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode du coude, nous voyons que la distance euclidienne entre deux points est inférieure à 0.025 pour 95% des couples de points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dendrogram\n",
    "\n",
    "Nous allons voir ici la hiérarchie des variables RFM. Ceci nous permettra d'anticiper un nombre \"idéal\" de clusters pour notre segmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "\n",
    "# Plot the hierarchical clustering of the scaled RFM variables\n",
    "if DRAW_PLOTS:\n",
    "    dendrogram(\n",
    "        linkage(scaled_rfm_df.sample(frac=0.5, random_state=42), method=\"ward\"),\n",
    "        truncate_mode=\"level\",\n",
    "        p=2,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons qu'avec 4 clusters, nous sommes dans la zone la plus large entre deux nouveaux clusters. Une segmentation à 2, 5 ou 6 clusters seraient aussi possibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA (Principal Component Analysis)\n",
    "\n",
    "Nous allons voir ici la projection des variables RFM sur les deux premières composantes principales. Ceci nous permettra de voir à quel point il sera difficile de segmenter nos clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "if DRAW_PLOTS:\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    data_pca = pca.fit_transform(scaled_rfm_df)\n",
    "\n",
    "    # Plot the data in the PCA space\n",
    "    fig = px.scatter(\n",
    "        x=data_pca[:1000, 0],\n",
    "        y=data_pca[:1000, 1],\n",
    "        trendline=\"ols\",\n",
    "        title=\"PCA 2D\",\n",
    "        opacity=0.5,\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        labels={\"x\": \"PCA 1\", \"y\": \"PCA 2\"},\n",
    "    )\n",
    "\n",
    "    # Plot the feature importances in the PCA space\n",
    "    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "    for i, feature in enumerate(rfm_df.columns):\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=0,\n",
    "            y0=0,\n",
    "            x1=loadings[i, 0],\n",
    "            y1=loadings[i, 1],\n",
    "            line=dict(color=\"red\", width=3),\n",
    "            name=feature,\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            x=loadings[i, 0],\n",
    "            y=loadings[i, 1],\n",
    "            ax=0,\n",
    "            ay=0,\n",
    "            xanchor=\"center\",\n",
    "            yanchor=\"bottom\",\n",
    "            text=feature,\n",
    "            name=feature,\n",
    "        )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que nos données ne semblent pas très facilement segmentables dans cet espace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import ClusterMixin\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,  # higher is better : https://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient\n",
    "    davies_bouldin_score,  # lower is better : https://scikit-learn.org/stable/modules/clustering.html#davies-bouldin-index\n",
    "    calinski_harabasz_score,  # higher is better : https://scikit-learn.org/stable/modules/clustering.html#calinski-harabasz-index\n",
    ")\n",
    "\n",
    "\n",
    "models_results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"n_clusters\",\n",
    "        \"labels\",\n",
    "        \"cluster_centers\",\n",
    "        \"inertia\",\n",
    "        \"time\",\n",
    "        \"silhouette_score\",\n",
    "        \"davies_bouldin_score\",\n",
    "        \"calinski_harabasz_score\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def process_model(\n",
    "    model_class: ClusterMixin,\n",
    "    model_args: dict,\n",
    "    param_name: str,\n",
    "    param_range: list,\n",
    "    fit_df: pd.DataFrame,\n",
    "    pred_df: pd.DataFrame,\n",
    "    verbose: bool = False,\n",
    ") -> dict:\n",
    "    results = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"model\",\n",
    "            \"n_clusters\",\n",
    "            \"labels\",\n",
    "            \"cluster_centers\",\n",
    "            \"inertia\",\n",
    "            \"time\",\n",
    "            \"silhouette_score\",\n",
    "            \"davies_bouldin_score\",\n",
    "            \"calinski_harabasz_score\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for param_value in param_range:\n",
    "        model_args[param_name] = param_value\n",
    "        model = model_class(**model_args)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\">>> Model : { model }\")\n",
    "\n",
    "        if hasattr(model, \"fit\") and hasattr(model, \"predict\"):\n",
    "            start_time = time()\n",
    "            model.fit(fit_df)\n",
    "            fit_time = (time() - start_time) / fit_df.shape[0]\n",
    "\n",
    "            start_time = time()\n",
    "            predicted_labels = model.predict(pred_df)\n",
    "            pred_time = (time() - start_time) / pred_df.shape[0]\n",
    "\n",
    "            fit_pred_time = fit_time + pred_time\n",
    "        elif hasattr(model, \"fit_predict\"):\n",
    "            start_time = time()\n",
    "            predicted_labels = model.fit_predict(pred_df)\n",
    "            fit_pred_time = time() - start_time\n",
    "        else:\n",
    "            raise ValueError(f\"{model} is not a clustering model.\")\n",
    "\n",
    "        n_clusters = predicted_labels.max() + 1\n",
    "        if verbose:\n",
    "            print(f\"Number of clusters : { n_clusters }\")\n",
    "\n",
    "        if not 1 < n_clusters < 11:\n",
    "            continue\n",
    "\n",
    "        result = {\n",
    "            \"model\": str(model)\n",
    "            .replace(\", random_state=42\", \"\")\n",
    "            .replace(\", n_jobs=-1\", \"\")\n",
    "            .replace(\"(random_state=42\", \"(\")\n",
    "            .replace(\"(n_jobs=-1\", \"(\"),\n",
    "            \"n_clusters\": n_clusters,\n",
    "            \"labels\": predicted_labels,\n",
    "            \"cluster_centers\": model.cluster_centers_\n",
    "            if hasattr(model, \"cluster_centers_\")\n",
    "            else None,\n",
    "            \"inertia\": model.inertia_ if hasattr(model, \"inertia_\") else None,\n",
    "            \"fit_pred_time\": fit_pred_time,\n",
    "            \"silhouette_score\": silhouette_score(\n",
    "                pred_df, predicted_labels, random_state=42\n",
    "            ),\n",
    "            \"davies_bouldin_score\": davies_bouldin_score(\n",
    "                pred_df, predicted_labels\n",
    "            ),\n",
    "            \"calinski_harabasz_score\": calinski_harabasz_score(\n",
    "                pred_df, predicted_labels\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Score : { round(result['silhouette_score'], 3) }\")\n",
    "\n",
    "        results = results.append(result, ignore_index=True)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_scores(results: pd.DataFrame) -> None:\n",
    "    fig = px.line(\n",
    "        results,\n",
    "        x=\"model\",\n",
    "        y=[\n",
    "            \"silhouette_score\",\n",
    "            \"davies_bouldin_score\",\n",
    "        ],\n",
    "        title=\"Clustering models evaluation\",\n",
    "        markers=True,\n",
    "        width=800,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_clusters(model_name, pred_df, labels, cluster_centers=None) -> None:\n",
    "    fig = px.scatter_3d(\n",
    "        pred_df,\n",
    "        x=\"recency\",\n",
    "        y=\"frequency\",\n",
    "        z=\"monetary\",\n",
    "        title=f\"Clustering : { model_name }\",\n",
    "        color=labels,\n",
    "        opacity=0.5,\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    if cluster_centers is not None:\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=cluster_centers[:, 0],\n",
    "                y=cluster_centers[:, 1],\n",
    "                z=cluster_centers[:, 2],\n",
    "                mode=\"markers\",\n",
    "                marker_symbol=\"x\",\n",
    "                hovertemplate=\"recency: %{x}, frequency: %{y}, monetary: %{z}\",\n",
    "                text=\"Cluster Center\",\n",
    "                name=\"Cluster Center\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_boxes(model_name, pred_df, labels, cluster_centers=None) -> None:\n",
    "    pred_df[\"labels\"] = labels\n",
    "\n",
    "    fig = px.box(\n",
    "        rfm_df,\n",
    "        title=f\"{ model_name } - Recency : days since last purchase\",\n",
    "        x=\"recency\",\n",
    "        color=\"labels\",\n",
    "        width=800,\n",
    "    )\n",
    "    fig.update_traces(boxmean=\"sd\")\n",
    "    fig.update_traces(notched=True)\n",
    "    fig.show()\n",
    "\n",
    "    fig = px.box(\n",
    "        rfm_df,\n",
    "        title=f\"{ model_name } - Frequency : total number of purchases\",\n",
    "        x=\"frequency\",\n",
    "        color=\"labels\",\n",
    "        width=800,\n",
    "    )\n",
    "    fig.update_traces(boxmean=\"sd\")\n",
    "    fig.update_traces(notched=True)\n",
    "    fig.show()\n",
    "\n",
    "    fig = px.box(\n",
    "        rfm_df,\n",
    "        title=f\"{ model_name } - Monetary : average purchase value\",\n",
    "        x=\"monetary\",\n",
    "        color=\"labels\",\n",
    "        width=800,\n",
    "    )\n",
    "    fig.update_traces(boxmean=\"sd\")\n",
    "    fig.update_traces(notched=True)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=KMeans,\n",
    "    model_args={\"random_state\": 42},\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df,\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniBatchKMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=MiniBatchKMeans,\n",
    "    model_args={\"random_state\": 42},\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df,\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AffinityPropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=AffinityPropagation,\n",
    "    model_args={\"random_state\": 42},\n",
    "    param_name=\"damping\",\n",
    "    param_range=[round(e, 3) for e in np.linspace(0.85, 0.99, 10)],\n",
    "    fit_df=scaled_rfm_df.sample(frac=0.1, random_state=42),\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "fit_pred_df = scaled_rfm_df.sample(frac=0.5, random_state=42)\n",
    "results = process_model(\n",
    "    model_class=AgglomerativeClustering,\n",
    "    model_args={},\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=fit_pred_df,\n",
    "    pred_df=fit_pred_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeanShift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=MeanShift,\n",
    "    model_args={\"n_jobs\": -1},\n",
    "    param_name=\"bandwidth\",\n",
    "    param_range=[round(e, 1) for e in np.linspace(0.5, 5, 10)],\n",
    "    fit_df=scaled_rfm_df.sample(frac=0.1, random_state=42),\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpectralClustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "\n",
    "fit_pred_df = scaled_rfm_df.sample(frac=0.2, random_state=42)\n",
    "results = process_model(\n",
    "    model_class=SpectralClustering,\n",
    "    model_args={\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    },\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=fit_pred_df,\n",
    "    pred_df=fit_pred_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if second_best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "fit_pred_df = scaled_rfm_df.sample(frac=0.5, random_state=42)\n",
    "results = process_model(\n",
    "    model_class=DBSCAN,\n",
    "    model_args={\n",
    "        \"n_jobs\": -1,\n",
    "    },\n",
    "    param_name=\"eps\",\n",
    "    param_range=[round(e, 2) for e in np.linspace(0.1, 1.5, 10)],\n",
    "    fit_df=fit_pred_df,\n",
    "    pred_df=fit_pred_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if second_best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "\n",
    "fit_pred_df = scaled_rfm_df.sample(frac=0.5, random_state=42)\n",
    "results = process_model(\n",
    "    model_class=OPTICS,\n",
    "    model_args={\n",
    "        \"n_jobs\": -1,\n",
    "    },\n",
    "    param_name=\"min_samples\",\n",
    "    param_range=[round(e, 4) for e in np.linspace(0.001, 0.004, 10)],\n",
    "    fit_df=fit_pred_df,\n",
    "    pred_df=fit_pred_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df.head(1000)),\n",
    "        columns=fit_pred_df.columns,\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if second_best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=pd.DataFrame(\n",
    "        scaler.inverse_transform(fit_pred_df), columns=fit_pred_df.columns\n",
    "    ),\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=Birch,\n",
    "    model_args={},\n",
    "    param_name=\"n_clusters\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df.sample(frac=0.2, random_state=42),\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM (Gaussian Mixture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=GaussianMixture,\n",
    "    model_args={\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "    param_name=\"n_components\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df,\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Gaussian Mixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "\n",
    "results = process_model(\n",
    "    model_class=BayesianGaussianMixture,\n",
    "    model_args={\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "    param_name=\"n_components\",\n",
    "    param_range=list(range(2, 11)),\n",
    "    fit_df=scaled_rfm_df,\n",
    "    pred_df=scaled_rfm_df,\n",
    ")\n",
    "plot_scores(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.sort_values(by=\"silhouette_score\", ascending=False).iloc[\n",
    "    0\n",
    "]\n",
    "models_results = models_results.append(best_result, ignore_index=True)\n",
    "\n",
    "plot_clusters(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(best_result[\"cluster_centers\"])\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_result = results.sort_values(\n",
    "    by=\"silhouette_score\", ascending=False\n",
    ").iloc[1]\n",
    "plot_clusters(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df.head(1000),\n",
    "    labels=second_best_result[\"labels\"][:1000],\n",
    "    cluster_centers=scaler.inverse_transform(\n",
    "        second_best_result[\"cluster_centers\"]\n",
    "    )\n",
    "    if best_result[\"cluster_centers\"] is not None\n",
    "    else None,\n",
    ")\n",
    "plot_boxes(\n",
    "    model_name=second_best_result[\"model\"],\n",
    "    pred_df=rfm_df,\n",
    "    labels=second_best_result[\"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results.sort_values(by=\"silhouette_score\", ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be314e25828437bbfaa596710b5d5ad2d634d57ddd0b964109bc8b248d9c7711"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
